{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2w2iKeHHMwVZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))"
      ],
      "metadata": {
        "id": "fyZhvfOHOH7w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExampleDeepNeuralNetwork(nn.Module):\n",
        "  def __init__(self, layer_sizes, use_shortcut):\n",
        "    super().__init__()\n",
        "    self.use_shortcut = use_shortcut\n",
        "    self.layers = nn.ModuleList([\n",
        "        nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]),GELU()),\n",
        "        nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]),GELU()),\n",
        "        nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]),GELU()),\n",
        "        nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]),GELU()),\n",
        "        nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]),GELU()),\n",
        "    ])\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.layers:\n",
        "      layer_output = layer(x)\n",
        "      if self.use_shortcut and x.shape == layer_output.shape:\n",
        "        x = x + layer_output\n",
        "      else:\n",
        "        x = layer_output\n",
        "    return x"
      ],
      "metadata": {
        "id": "7j8IxItvNGlz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
        "sample_input = torch.tensor([[1., 0., -1.]])\n",
        "torch.manual_seed(123)\n",
        "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
        "layer_sizes, use_shortcut=False\n",
        ")"
      ],
      "metadata": {
        "id": "WdXXGZAbOmyV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_gradients(model, x):\n",
        "  output = model(x)\n",
        "  target = torch.tensor([[0.]])\n",
        "  loss = nn.MSELoss()\n",
        "  loss = loss(output, target)\n",
        "  loss.backward()\n",
        "\n",
        "  for name, param in model.named_parameters():\n",
        "    if 'weight' in name:\n",
        "      print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
      ],
      "metadata": {
        "id": "7VWdEt4-Oo0j"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_gradients(model_without_shortcut, sample_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcfzO9JuPGzO",
        "outputId": "aada0d6d-00c9-436f-e673-87fc54bb9ed7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layers.0.0.weight has gradient mean of 0.00020173584925942123\n",
            "layers.1.0.weight has gradient mean of 0.00012011159560643137\n",
            "layers.2.0.weight has gradient mean of 0.0007152040489017963\n",
            "layers.3.0.weight has gradient mean of 0.0013988736318424344\n",
            "layers.4.0.weight has gradient mean of 0.005049645435065031\n"
          ]
        }
      ]
    }
  ]
}