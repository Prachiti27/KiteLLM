{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g4eKDPw3biwE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "vocab_size = 50257\n",
        "output_dim = 256\n",
        "\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "CqO3S0Y2elsC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\",\"r\",encoding=\"utf-8\") as f:\n",
        "  raw_text = f.read()\n",
        "\n",
        "enc_text = tokenizer.encode(raw_text)\n",
        "print(len(enc_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvJTU_gnfgGU",
        "outputId": "89eb352e-fe63-484a-d970-68d2c406ffb8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self, txt, tokenizer, max_length, stride):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "    for i in range(0, len(token_ids) - max_length, stride):\n",
        "      input_chunk = token_ids[i:i + max_length]\n",
        "      target_chunk = token_ids[i+1:i+max_length+1]\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "3tCP3oFUfQ8H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloaderV1(txt, batch_size=4, max_length=256, stride=128, shuffle=True,drop_last=True, num_workers=0):\n",
        "  tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "  dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "  dataloader = DataLoader(\n",
        "      dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=shuffle,\n",
        "      drop_last=drop_last,\n",
        "      num_workers=num_workers\n",
        "  )\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "Dh2Q6U_NfR6I"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 4\n",
        "dataloader = create_dataloaderV1(\n",
        "    raw_text, batch_size = 8, max_length = max_length, stride = max_length, shuffle = False\n",
        ")\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)"
      ],
      "metadata": {
        "id": "rZZxR3AMfUgS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Token IDs:\\n\", inputs)\n",
        "print(\"\\nInputs shape:\\n\",inputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKGwIQFgfzrc",
        "outputId": "5a8ac719-43e5-4fd5-ab31-b09a4144f731"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "\n",
            "Inputs shape:\n",
            " torch.Size([8, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings = token_embedding_layer(inputs)\n",
        "print(token_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFPZsIiof59M",
        "outputId": "a2b81615-5b80-4b5b-c5b2-7055f45a438f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = max_length\n",
        "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)"
      ],
      "metadata": {
        "id": "KfscgXmZhejP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_embeddings = pos_embedding_layer(torch.arange(max_length))"
      ],
      "metadata": {
        "id": "pfuQqniXh5DS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pos_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIrlglB8ioD1",
        "outputId": "ec3a7a39-0e2b-4d27-8e88-14ab1de014e9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_embedding = token_embeddings + pos_embeddings"
      ],
      "metadata": {
        "id": "LpgPngx5iqSG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_embedding.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c36XrChRi_i7",
        "outputId": "e41fe685-6620-48a3-e68b-3515865d528b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    }
  ]
}